{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.cross_validation import KFold\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    if len(text) >5:\n",
    "        tokenizer = RegexpTokenizer('\\w+')#('\\w+|\\$[\\d\\.]+|\\S+')#  #tokenizer that picks out sequences of alphanumeric characters as tokens and drops everything else\n",
    "        tokens=tokenizer.tokenize(text)\n",
    "        final_tokens = []\n",
    "        #print(tokens)\n",
    "        if len(tokens) > 2:\n",
    "            for text in tokens:\n",
    "                if text not in stop and len(text)>2:\n",
    "                    final_tokens.append(text)\n",
    "        else:\n",
    "            final_tokens = tokens\n",
    "        #print(final_tokens)                \n",
    "        stems = stem_tokens(final_tokens, stemmer)\n",
    "        #print stems\n",
    "        return stems\n",
    "        #return tokens\n",
    "    else :\n",
    "        return text.split(' ')\n",
    "\n",
    "\n",
    "problem = pd.read_csv('reddit_train_top20', encoding = 'utf-8')\n",
    "#print(problem[problem.title.str.len() <5])\n",
    "problem = problem.drop_duplicates(take_last = True)\n",
    "problem = problem.drop(problem[problem.duplicated('title') == True].index)\n",
    "#problem = problem.drop(problem.title.str.len() <5)Re\n",
    "problem['subreddit'] = problem['subreddit'].str.lower()\n",
    "problem['title'] = problem['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ps4] lf5m (who has) hm gate keeper cp.</td>\n",
       "      <td>fireteams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pov view in competitive</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if you were given the chance to go back and re...</td>\n",
       "      <td>askreddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[h] fn howl 0.04fv + mw vulcan [w] knife offers</td>\n",
       "      <td>globaloffensivetrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop pressing the button</td>\n",
       "      <td>thebutton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the bathmat is a towel for your feet.</td>\n",
       "      <td>showerthoughts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reddit, what is your best quiz team name?</td>\n",
       "      <td>askreddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>two swedes experiencing norwegian svalbard</td>\n",
       "      <td>videos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the grass is greener on the other side of the ...</td>\n",
       "      <td>showerthoughts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>just got a stattrak vulcan fn</td>\n",
       "      <td>globaloffensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[h] 80% market gut safari ww [w] 13k</td>\n",
       "      <td>globaloffensivetrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[h] collector's slaughter, triple pattern, dia...</td>\n",
       "      <td>globaloffensivetrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>examiners/teachers etc. what is the oddest bri...</td>\n",
       "      <td>askreddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is the sport of boxing dying or dead already?</td>\n",
       "      <td>askreddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>assuming it would be obedient and docile, if y...</td>\n",
       "      <td>askreddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[ps4] lf5m crota's end nm crota cp</td>\n",
       "      <td>fireteams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sometimes, a theory must be tested.</td>\n",
       "      <td>adviceanimals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>music poll! for great science!</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sleeping is just the person controlling us tur...</td>\n",
       "      <td>showerthoughts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jeez its like parking is a big deal or somethi...</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title             subreddit\n",
       "0             [ps4] lf5m (who has) hm gate keeper cp.             fireteams\n",
       "1                             pov view in competitive       leagueoflegends\n",
       "2   if you were given the chance to go back and re...             askreddit\n",
       "3     [h] fn howl 0.04fv + mw vulcan [w] knife offers  globaloffensivetrade\n",
       "4                            stop pressing the button             thebutton\n",
       "5               the bathmat is a towel for your feet.        showerthoughts\n",
       "6           reddit, what is your best quiz team name?             askreddit\n",
       "7          two swedes experiencing norwegian svalbard                videos\n",
       "8   the grass is greener on the other side of the ...        showerthoughts\n",
       "9                       just got a stattrak vulcan fn       globaloffensive\n",
       "10               [h] 80% market gut safari ww [w] 13k  globaloffensivetrade\n",
       "11  [h] collector's slaughter, triple pattern, dia...  globaloffensivetrade\n",
       "12  examiners/teachers etc. what is the oddest bri...             askreddit\n",
       "13      is the sport of boxing dying or dead already?             askreddit\n",
       "14  assuming it would be obedient and docile, if y...             askreddit\n",
       "15                 [ps4] lf5m crota's end nm crota cp             fireteams\n",
       "16                sometimes, a theory must be tested.         adviceanimals\n",
       "17                     music poll! for great science!                 music\n",
       "19  sleeping is just the person controlling us tur...        showerthoughts\n",
       "20  jeez its like parking is a big deal or somethi...                 funny"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "final_pipeline = Pipeline((\n",
    "    ('vec', CountVectorizer(binary = True, analyzer='word',#tokenizer=tokenize,\n",
    "                            lowercase=True, max_df = 0.3)),#stop_words='english',\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    #('vec', TfidfVectorizer(tokenizer=tokenize,\n",
    "                            #max_df = 0.3,ngram_range = (1,1),norm = 'l2',use_idf = False, binary=True)),\n",
    "    ('chi2', SelectKBest(chi2, k= 1000)),\n",
    "    #('clf', svm.SVC()),\n",
    "    ('clf', BernoulliNB()),\n",
    "    #('clf', MultinomialNB()),\n",
    "    #('clf', GaussianNB()),        \n",
    "))\n",
    "#parameters = {\n",
    "    #'vec__max_df': (0.3, 0.4, 0.5),#, 0.75, 1.0),\n",
    "    #'vec__ngram_range': ((1, 1), (2, 2), (2,3)),  # unigrams or bigrams\n",
    "    #'vec__use_idf': (True, False),\n",
    "    #'vec__norm': ('l1', 'l2'),\n",
    "#}\n",
    "#grid_search = GridSearchCV(final_pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "#t0 = time()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.601829666739\n",
      "0.602918754084\n",
      "0.590285340884\n",
      "0.585185185185\n",
      "0.593464052288\n",
      "0.598474945534\n",
      "Avg accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(problem.shape[0], n_folds=6, shuffle=True)\n",
    "scores = []\n",
    "\n",
    "for train_indices, test_indices in kf:\n",
    "    train_text = problem.iloc[train_indices]['title'].values\n",
    "    train_class = problem.iloc[train_indices]['subreddit'].values\n",
    "\n",
    "    test_text = problem.iloc[test_indices]['title'].values\n",
    "    test_class = problem.iloc[test_indices]['subreddit'].values\n",
    "\n",
    "    final_pipeline.fit(train_text, train_class)\n",
    "    predicted = final_pipeline.predict(test_text)\n",
    "    #print(predicted)\n",
    "    #print(class_test)\n",
    "    print(np.mean(predicted == test_class))\n",
    "    scores.append(np.mean(predicted == test_class))\n",
    "    #print(metrics.classification_report(test_class, predicted))\n",
    "    #grid_search.fit(train_text, train_class)\n",
    "    #print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    #print(\"Best parameters set:\")\n",
    "    #best_parameters = grid_search.best_estimator_.get_params()\n",
    "    #for param_name in sorted(parameters.keys()):\n",
    "        #print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "print 'Avg accuracy: %.2f' % (sum(scores)/len(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "globaloffensive     : 07pm 2050 1941 3200x1800 2015_kungfu 20mins 60s 2x1 640x480 5x\n",
      "newsofiran          : 2015_kungfu 169 4600 8300 2050 3200x1800 640x480 5x 83 77\n",
      "betternews          : 1vs1 1941 3200x1800 2050 281 07pm 60s 640x480 5x 2x1\n",
      "videos              : 03日 1000 07pm 7k 32t 1941 5x 3200x1800 640x480 2015_kungfu\n",
      "funny               : 170k 1941 83 3200x1800 07pm 2050 2015_kungfu 148 640x480 5x\n",
      "thebutton           : 77 3200x1800 169 2009 640x480 07pm 2050 5x 7850k 180keys\n",
      "dota2               : 1307 1955 24fv 152 800k 1559 1941 70keys 2004 40متری\n",
      "adviceanimals       : 07pm 1941 83 2050 2015_kungfu 3200x1800 2x1 60s 640x480 5x\n",
      "showerthoughts      : 2050 2x1 32t 07pm 1941 2015_kungfu 1972 640x480 3200x1800 5x\n",
      "pics                : 157 7k 2x1 1941 2015_kungfu 07pm 32t 2050 5x 640x480\n",
      "aww                 : 520 1182 10x 2x 21s 1901 195k 260x 1939 220k\n",
      "askreddit           : 1972 7k 32t 07pm 1941 2050 2015_kungfu 3200x1800 640x480 5x\n",
      "music               : 7k 2050 83 2015_kungfu 2v2s 07pm 640x480 3200x1800 49 5x\n",
      "leagueoflegends     : 5s 2050 100k 32t 1941 07pm 3200x1800 5x 640x480 2015_kungfu\n",
      "explainlikeimfive   : abroad 960 8mln aca 8k act acidente 9pm 8agfib9n ability\n",
      "news                : 32t 60s 1941 07pm 378 3200x1800 2050 2x1 5x 640x480\n",
      "pcmasterrace        : 83 2050 32t 07pm 640x480 3200x1800 2015_kungfu 60s 2x1 5x\n",
      "gaming              : 1v4 20mins 2015_kungfu 110 07pm 2012 2050 3200x1800 640x480 5x\n",
      "globaloffensivetrade: 3200x1800 77 460 2x1 07pm 2050 20mins 640x480 125k 5x\n",
      "fireteams           : 2050 1941 7k 32t 60s 07pm 2015_kungfu 3200x1800 640x480 5x\n"
     ]
    }
   ],
   "source": [
    "#Original code extracted from http://stackoverflow.com/questions/11116697/how-to-get-most-informative-features-for-scikit-learn-classifiers\n",
    "\n",
    "\n",
    "def print_top10(vectorizer, clf, class_labels):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "        #print(\"%s== %s\" % (class_label,\n",
    "        #      \" \".join(feature_names[j] for j in top10)))\n",
    "        print(\"{:<20}: \".format(class_label)+\n",
    "              \" \".join(feature_names[j] for j in top10))\n",
    "C_V=final_pipeline.steps[0][1] #CountVectorizer\n",
    "B_NB=final_pipeline.steps[2][1] #BernoulliNB\n",
    "categories=list(set(problem.subreddit.values))\n",
    "print_top10(C_V,B_NB,categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603498993652\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       adviceanimals       0.22      0.04      0.07       821\n",
      "           askreddit       0.75      0.86      0.80      5720\n",
      "                 aww       0.54      0.30      0.39       959\n",
      "          betternews       0.70      0.27      0.39       925\n",
      "               dota2       0.82      0.39      0.53       829\n",
      "   explainlikeimfive       0.89      0.91      0.90       786\n",
      "           fireteams       0.99      0.99      0.99      3586\n",
      "               funny       0.21      0.58      0.31      2339\n",
      "              gaming       0.45      0.22      0.29      1147\n",
      "     globaloffensive       0.59      0.28      0.38       949\n",
      "globaloffensivetrade       0.96      0.95      0.95      2074\n",
      "     leagueoflegends       0.57      0.54      0.55      2161\n",
      "               music       0.76      0.43      0.55       816\n",
      "                news       0.33      0.46      0.39      1650\n",
      "          newsofiran       1.00      0.99      0.99      1619\n",
      "        pcmasterrace       0.64      0.29      0.40       781\n",
      "                pics       0.27      0.17      0.21      1365\n",
      "      showerthoughts       0.43      0.43      0.43      1321\n",
      "           thebutton       0.82      0.47      0.59       903\n",
      "              videos       0.26      0.16      0.20      1544\n",
      "\n",
      "         avg / total       0.64      0.60      0.60     32295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_problem = pd.read_csv('reddit_test_top20', encoding = 'utf-8')\n",
    "target_problem.head(20)\n",
    "\n",
    "target_problem = target_problem.drop_duplicates(take_last = True)\n",
    "target_problem = target_problem.drop(target_problem[target_problem.duplicated('title') == True].index)\n",
    "target_problem['subreddit'] = target_problem['subreddit'].str.lower()\n",
    "target_problem['title'] = target_problem['title'].str.lower()\n",
    "predicted = final_pipeline.predict(target_problem['title'])\n",
    "\n",
    "names=sorted(list(set(target_problem['subreddit'])))\n",
    "print(np.mean(predicted == target_problem['subreddit']))\n",
    "print(metrics.classification_report(target_problem['subreddit'],\n",
    "                                    predicted,target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use another classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#text_train = problem['title']\n",
    "#class_train = problem['subreddit']\n",
    "#text_train_small, text_validation, class_train_small, class_validation = train_test_split(\n",
    "#    text_train, class_train, test_size=.2, random_state=42)\n",
    "pipeline2 = Pipeline((\n",
    "    ('vec', CountVectorizer(#binary = True, \n",
    "                            analyzer='word',#tokenizer=tokenize,\n",
    "                            lowercase=True, max_df = 0.3)),#stop_words='english',\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    #('vec', TfidfVectorizer(tokenizer=tokenize,\n",
    "                            #max_df = 0.3,ngram_range = (1,1),norm = 'l2',use_idf = False, binary=True)),\n",
    "    ('chi2', SelectKBest(chi2, k= 1000)),\n",
    "    #('clf', svm.SVC()),\n",
    "    #('clf', BernoulliNB()),\n",
    "    ('clf', MultinomialNB(alpha=0.5)),\n",
    "    #('clf', GaussianNB()),        \n",
    "))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57852319756\n",
      "0.579612284905\n",
      "0.590720975822\n",
      "0.571895424837\n",
      "0.575163398693\n",
      "0.581045751634\n",
      "Avg accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(problem.shape[0], n_folds=6, shuffle=True)\n",
    "scores = []\n",
    "\n",
    "for train_indices, test_indices in kf:\n",
    "    train_text = problem.iloc[train_indices]['title'].values\n",
    "    train_class = problem.iloc[train_indices]['subreddit'].values\n",
    "\n",
    "    test_text = problem.iloc[test_indices]['title'].values\n",
    "    test_class = problem.iloc[test_indices]['subreddit'].values\n",
    "\n",
    "    pipeline2.fit(train_text, train_class)\n",
    "    predicted = pipeline2.predict(test_text)\n",
    "    #print(predicted)\n",
    "    #print(class_test)\n",
    "    print(np.mean(predicted == test_class))\n",
    "    scores.append(np.mean(predicted == test_class))\n",
    "    #print(metrics.classification_report(test_class, predicted))\n",
    "    #grid_search.fit(train_text, train_class)\n",
    "    #print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    #print(\"Best parameters set:\")\n",
    "    #best_parameters = grid_search.best_estimator_.get_params()\n",
    "    #for param_name in sorted(parameters.keys()):\n",
    "        #print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "print 'Avg accuracy: %.2f' % (sum(scores)/len(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
